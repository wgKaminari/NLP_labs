{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69983e8f",
   "metadata": {},
   "source": [
    "# **``TF-IDF``**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80cb2677",
   "metadata": {},
   "source": [
    "![Alt texts](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25386bd",
   "metadata": {},
   "source": [
    "## **Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84cd71a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import nltk\n",
    "from nltk.corpus import treebank\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec5dbb78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Розмір матриці TF-IDF: (199, 11036)\n",
      "Загальна кількість унікальних термінів: 11036\n",
      "\n",
      "Топ-20 термінів за TF-IDF:\n",
      "          term  non_zero_docs  mean_tfidf\n",
      "3461        mr             82    0.735963\n",
      "9273        he             80    0.696529\n",
      "10070     that            127    0.692223\n",
      "10850     says             32    0.688334\n",
      "5404        us             67    0.672095\n",
      "2460      they             83    0.669513\n",
      "3089      have             97    0.661569\n",
      "3295       are             98    0.654389\n",
      "5264        at            111    0.654083\n",
      "8323     their             55    0.651955\n",
      "2580       but             97    0.649064\n",
      "4409     would             76    0.638284\n",
      "7580    market             53    0.625163\n",
      "8726   million            109    0.624915\n",
      "10364       as            114    0.621238\n",
      "243         or             99    0.618202\n",
      "2547        nt            102    0.617928\n",
      "10969     more             80    0.613188\n",
      "8889        t2            109    0.609510\n",
      "7689        t1            135    0.609084\n",
      "\n",
      "Кількість документів з ненульовими TF-IDF значеннями:\n",
      "[  24   23  339  189   37   39   53   73   50  245  100  197  251   52\n",
      "  236   73   49  388   57  288  121  203   57   96   53  118  159   19\n",
      "  170   22   54   58   61  383  154  483  817   91  456   81  581   42\n",
      "  427  952  395   57  318  430  721   46  350   65   35   61   25   33\n",
      "  223   37  342  235   34  485  231  277   54   35  194   57   37   83\n",
      "  578  248   94   58  219   38  191   40   46  299   84  420  436   80\n",
      "  519   57  187  390  671  485  124  170  413  165  120  563  411  277\n",
      "   48  400  398  423  242   27  453   76  238  456  447  267  278  563\n",
      "  277  433   69  388  262 1278  263  495  405   57  231  122  283  308\n",
      "  110  446  138  411   49  105   49   96   68   94  500  110   34  118\n",
      "  216  589   46  111   88  231   80  291  255   96  135   93  220   79\n",
      "  496  100  100  188  114   85   92  473   84  113   98  149   79   93\n",
      "   94   87  114   97  125  431   96  114  107  327  418  104  138  111\n",
      "  125  188   30  488  153  136  165   55   22  553   40  328   22   35\n",
      "   36  160   34]\n"
     ]
    }
   ],
   "source": [
    "class TFIDFVectorizer:\n",
    "    def __init__(self, preprocessing=None):\n",
    "        self.vocabulary = set()\n",
    "        self.document_frequency = defaultdict(int)\n",
    "        self.idf_values = {}\n",
    "        self.documents = []\n",
    "        self.file_ids = []\n",
    "        self.preprocessing = self._default_preprocessor\n",
    "\n",
    "    def _default_preprocessor(self, text):\n",
    "        # Якщо текст - список, перетворюємо на рядок\n",
    "        if isinstance(text, list):\n",
    "            text = ' '.join(text)\n",
    "        \n",
    "        # Перетворення на нижній регістр та видалення зайвих символів\n",
    "        text = text.lower()\n",
    "        text = re.sub(r'[^\\w\\s]', '', text)\n",
    "        return text\n",
    "\n",
    "    def _preprocess_text(self, text):\n",
    "        # Якщо текст - список слів, перетворюємо на рядок\n",
    "        if isinstance(text, list):\n",
    "            text = ' '.join(text)\n",
    "        \n",
    "        # Якщо текст є об'єктом StreamBackedCorpusView\n",
    "        try:\n",
    "            text = ' '.join(text)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Застосовуємо додаткову обробку \n",
    "        return self.preprocessing(text)\n",
    "\n",
    "    def _counter(self, document, term):\n",
    "        return document.split().count(term)\n",
    "\n",
    "    def _compute_document_frequency(self):\n",
    "        self.document_frequency.clear()\n",
    "        self.vocabulary.clear()\n",
    "        \n",
    "        for document in self.documents:\n",
    "            unique_terms = set(document.split())\n",
    "            for term in unique_terms:\n",
    "                self.document_frequency[term] += 1\n",
    "                self.vocabulary.add(term)\n",
    "\n",
    "    def _compute_idf(self):\n",
    "        document_count = len(self.documents)\n",
    "        self.idf_values = {\n",
    "            term: math.log((document_count + 1) / (freq + 1))\n",
    "            for term, freq in self.document_frequency.items()\n",
    "        }\n",
    "\n",
    "    def compute_tf(self, document, term):\n",
    "        count = self._counter(document, term)\n",
    "        return 1 + math.log(count) if count > 0 else 0\n",
    "\n",
    "    def compute_tf_idf(self, document, term):\n",
    "        tf = self.compute_tf(document, term)\n",
    "        idf = self.idf_values.get(term, 0)\n",
    "        return tf * idf\n",
    "\n",
    "    def load_treebank_corpus(self, preprocessing=None):\n",
    "        # Завантаження необхідних ресурсів NLTK\n",
    "        #nltk.download('treebank')\n",
    "        \n",
    "        # Очищення попередніх даних\n",
    "        self.documents.clear()\n",
    "        self.file_ids.clear()\n",
    "        \n",
    "        # Встановлення функції попередньої обробки\n",
    "        if preprocessing:\n",
    "            self.preprocessing = preprocessing\n",
    "        \n",
    "        # Обробка кожного файлу як окремого документа\n",
    "        for file_id in treebank.fileids():\n",
    "            # Отримання слів з файлу та перетворення на рядок\n",
    "            words = treebank.words(file_id)\n",
    "            processed_doc = self._preprocess_text(words)\n",
    "            self.documents.append(processed_doc)\n",
    "            self.file_ids.append(file_id)\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def fit(self):\n",
    "        # Обчислення частоти документів\n",
    "        self._compute_document_frequency()\n",
    "        \n",
    "        # Обчислення inverse document frequency\n",
    "        self._compute_idf()\n",
    "        \n",
    "        return self\n",
    "\n",
    "    def transform(self):\n",
    "        # Перевірка, чи була модель натренована\n",
    "        if not self.idf_values:\n",
    "            raise ValueError(\"Спочатку викличіть метод fit()\")\n",
    "        \n",
    "        # Створення матриці TF-IDF\n",
    "        tfidf_matrix = np.zeros((len(self.documents), len(self.vocabulary)))\n",
    "        \n",
    "        # Перетворення vocabulary в список для індексації\n",
    "        terms_list = list(self.vocabulary)\n",
    "        \n",
    "        # Обчислення TF-IDF для кожного документа та терміну\n",
    "        for doc_idx, doc in enumerate(self.documents):\n",
    "            for term_idx, term in enumerate(terms_list):\n",
    "                tfidf_matrix[doc_idx, term_idx] = self.compute_tf_idf(doc, term)\n",
    "        \n",
    "        return tfidf_matrix, terms_list\n",
    "\n",
    "    def fit_transform(self):\n",
    "        return self.fit().transform()\n",
    "\n",
    "    def analyze_tfidf_matrix(self, tfidf_matrix, terms_list):\n",
    "        # Підрахунок ненульових значень для кожного терміну\n",
    "        non_zero_counts = np.count_nonzero(tfidf_matrix, axis=0)\n",
    "        \n",
    "        # Обчислення середніх значень TF-IDF для кожного терміну\n",
    "        mean_tfidf = np.mean(tfidf_matrix, axis=0)\n",
    "        \n",
    "        # Створення DataFrame для аналізу\n",
    "        analysis_df = pd.DataFrame({\n",
    "            'term': terms_list,\n",
    "            'non_zero_docs': non_zero_counts,\n",
    "            'mean_tfidf': mean_tfidf\n",
    "        })\n",
    "        \n",
    "        # Сортування за середнім TF-IDF у спадному порядку\n",
    "        return analysis_df.sort_values('mean_tfidf', ascending=False)\n",
    "\n",
    "# Приклад використання з розширеним налагодженням\n",
    "if __name__ == \"__main__\":\n",
    "    # Створення векторизатора\n",
    "    vectorizer = TFIDFVectorizer()\n",
    "    \n",
    "    # Завантаження корпусу Treebank\n",
    "    vectorizer.load_treebank_corpus()\n",
    "    \n",
    "    # Обчислення матриці TF-IDF\n",
    "    tfidf_matrix, terms = vectorizer.fit_transform()\n",
    "    \n",
    "    # Виведення результатів\n",
    "    print(\"Розмір матриці TF-IDF:\", tfidf_matrix.shape)\n",
    "    print(\"Загальна кількість унікальних термінів:\", len(terms))\n",
    "    \n",
    "    # Аналіз матриці TF-IDF\n",
    "    analysis = vectorizer.analyze_tfidf_matrix(tfidf_matrix, terms)\n",
    "    \n",
    "    # Виведення топ-20 термінів за TF-IDF\n",
    "    print(\"\\nТоп-20 термінів за TF-IDF:\")\n",
    "    print(analysis.head(20))\n",
    "    \n",
    "    # Додаткова діагностика\n",
    "    print(\"\\nКількість документів з ненульовими TF-IDF значеннями:\")\n",
    "    print(np.count_nonzero(tfidf_matrix, axis=1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
