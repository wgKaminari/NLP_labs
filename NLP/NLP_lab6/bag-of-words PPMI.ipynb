{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef60e626",
   "metadata": {},
   "source": [
    "# **``bag-of-words/PPMI``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37657969",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.corpus import gutenberg\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "import string\n",
    "from collections import Counter, defaultdict\n",
    "import math\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbeb67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download('gutenberg')\n",
    "#nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    \"\"\"Попередня обробка тексту: нижній регістр, видалення пунктуації.\"\"\"\n",
    "    text = text.lower()\n",
    "    text = ''.join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "\n",
    "def tokenize_text(text):\n",
    "    \"\"\"Токенізація тексту на слова.\"\"\"\n",
    "    return word_tokenize(preprocess_text(text))\n",
    "\n",
    "def get_vocabulary(corpus):\n",
    "    \"\"\"Створення словника унікальних слів з корпусу.\"\"\"\n",
    "    vocabulary = set()\n",
    "    for doc in corpus:\n",
    "        words = tokenize_text(doc)\n",
    "        vocabulary.update(words)\n",
    "    return list(vocabulary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a7c0192",
   "metadata": {},
   "source": [
    "## **Task 0:** Реалізація Bag-of-Words для довільного тексту"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce72ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_bow_vectors(corpus):\n",
    "    \"\"\"Створення Bag-of-Words представлення для кожного документа в корпусі.\"\"\"\n",
    "    vocabulary = get_vocabulary(corpus)\n",
    "    vocab_to_idx = {word: i for i, word in enumerate(vocabulary)}\n",
    "    \n",
    "    bow_vectors = []\n",
    "    for doc in corpus:\n",
    "        vector = np.zeros(len(vocabulary))\n",
    "        words = tokenize_text(doc)\n",
    "        word_counts = Counter(words)\n",
    "        \n",
    "        for word, count in word_counts.items():\n",
    "            if word in vocab_to_idx:\n",
    "                vector[vocab_to_idx[word]] = count\n",
    "        \n",
    "        bow_vectors.append(vector)\n",
    "    \n",
    "    return bow_vectors, vocabulary, vocab_to_idx\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27adf812",
   "metadata": {},
   "source": [
    "## **Task 1:** Розширення для використання N-грам замість слів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea31dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ngram_bow_vectors(corpus, n=2):\n",
    "    \"\"\"Створення Bag-of-Words на основі N-грам.\"\"\"\n",
    "    all_ngrams = set()\n",
    "    \n",
    "    # Збір усіх N-грам з корпусу\n",
    "    for doc in corpus:\n",
    "        words = tokenize_text(doc)\n",
    "        doc_ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "        all_ngrams.update(doc_ngrams)\n",
    "    \n",
    "    ngram_to_idx = {ngram: i for i, ngram in enumerate(all_ngrams)}\n",
    "    \n",
    "    # Створення BoW векторів\n",
    "    ngram_bow_vectors = []\n",
    "    for doc in corpus:\n",
    "        vector = np.zeros(len(all_ngrams))\n",
    "        words = tokenize_text(doc)\n",
    "        doc_ngrams = [' '.join(words[i:i+n]) for i in range(len(words)-n+1)]\n",
    "        ngram_counts = Counter(doc_ngrams)\n",
    "        \n",
    "        for ngram, count in ngram_counts.items():\n",
    "            if ngram in ngram_to_idx:\n",
    "                vector[ngram_to_idx[ngram]] = count\n",
    "        \n",
    "        ngram_bow_vectors.append(vector)\n",
    "    \n",
    "    return ngram_bow_vectors, list(all_ngrams), ngram_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7dc37d6",
   "metadata": {},
   "source": [
    "## **Task 2:** Реалізація PPMI з підрахунком співзустрічань в межах одного параграфа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e278d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_paragraph_cooccurrence_matrix(corpus):\n",
    "    \"\"\"Створення матриці співзустрічань слів у межах параграфів.\"\"\"\n",
    "    # Розбиття корпусу на параграфи і токенізація\n",
    "    paragraphs = []\n",
    "    for doc in corpus:\n",
    "        paras = doc.split('\\n\\n')  # Розділення на параграфи\n",
    "        paragraphs.extend([preprocess_text(p) for p in paras if p.strip()])\n",
    "    \n",
    "    vocabulary = get_vocabulary(paragraphs)\n",
    "    vocab_size = len(vocabulary)\n",
    "    word_to_idx = {word: i for i, word in enumerate(vocabulary)}\n",
    "    \n",
    "    # Створення матриці співзустрічань\n",
    "    cooccurrence_matrix = np.zeros((vocab_size, vocab_size))\n",
    "    \n",
    "    for para in paragraphs:\n",
    "        words = tokenize_text(para)\n",
    "        word_indices = [word_to_idx[w] for w in words if w in word_to_idx]\n",
    "        \n",
    "        # Підрахунок співзустрічань у параграфі\n",
    "        for i in word_indices:\n",
    "            for j in word_indices:\n",
    "                if i != j:  # Виключаємо співзустрічання слова з самим собою\n",
    "                    cooccurrence_matrix[i, j] += 1\n",
    "    \n",
    "    return cooccurrence_matrix, vocabulary, word_to_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05d1000",
   "metadata": {},
   "source": [
    "## **Task 3:** Реалізація PPMI з підрахунком співзустрічань у вікні сусідніх слів"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f1d2ad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_window_cooccurrence_matrix(corpus, window_size=5):\n",
    "    \"\"\"Створення матриці співзустрічань слів у межах вікна.\"\"\"\n",
    "    vocabulary = get_vocabulary(corpus)\n",
    "    vocab_size = len(vocabulary)\n",
    "    word_to_idx = {word: i for i, word in enumerate(vocabulary)}\n",
    "    \n",
    "    # Створення матриці співзустрічань\n",
    "    cooccurrence_matrix = np.zeros((vocab_size, vocab_size))\n",
    "    \n",
    "    for doc in corpus:\n",
    "        words = tokenize_text(doc)\n",
    "        word_indices = [word_to_idx[w] for w in words if w in word_to_idx]\n",
    "        \n",
    "        # Підрахунок співзустрічань у вікні\n",
    "        for i, center_word_idx in enumerate(word_indices):\n",
    "            window_start = max(0, i - window_size)\n",
    "            window_end = min(len(word_indices), i + window_size + 1)\n",
    "            \n",
    "            for j in range(window_start, window_end):\n",
    "                if i != j:  # Виключаємо співзустрічання слова з самим собою\n",
    "                    context_word_idx = word_indices[j]\n",
    "                    cooccurrence_matrix[center_word_idx, context_word_idx] += 1\n",
    "    \n",
    "    return cooccurrence_matrix, vocabulary, word_to_idx\n",
    "\n",
    "# Функція для обчислення матриці PPMI на основі матриці співзустрічань\n",
    "def calculate_ppmi_matrix(cooccurrence_matrix):\n",
    "    \"\"\"Обчислення матриці PPMI на основі матриці співзустрічань.\"\"\"\n",
    "    # Сума всіх співзустрічань\n",
    "    total_count = np.sum(cooccurrence_matrix)\n",
    "    \n",
    "    # Обчислення маргінальних вірогідностей\n",
    "    word_marginals = np.sum(cooccurrence_matrix, axis=1) / total_count\n",
    "    context_marginals = np.sum(cooccurrence_matrix, axis=0) / total_count\n",
    "    \n",
    "    # Розрахунок матриці p_ij\n",
    "    p_ij = cooccurrence_matrix / total_count\n",
    "    \n",
    "    # Створення матриці PPMI\n",
    "    ppmi_matrix = np.zeros_like(cooccurrence_matrix, dtype=float)\n",
    "    \n",
    "    for i in range(cooccurrence_matrix.shape[0]):\n",
    "        for j in range(cooccurrence_matrix.shape[1]):\n",
    "            if p_ij[i, j] > 0:\n",
    "                pmi = np.log2(p_ij[i, j] / (word_marginals[i] * context_marginals[j]))\n",
    "                ppmi_matrix[i, j] = max(0, pmi)  # PPMI = max(PMI, 0)\n",
    "    \n",
    "    return ppmi_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f81f7",
   "metadata": {},
   "source": [
    "## **Task 4:** Вирішення проблеми рідких слів з високими значеннями PMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "796b14fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_smoothed_ppmi_matrix(cooccurrence_matrix, alpha=0.75):\n",
    "    \"\"\"Обчислення PPMI з використанням згладжування для рідких слів.\"\"\"\n",
    "    # Застосування згладжування до підрахунків співзустрічань\n",
    "    smoothed_matrix = np.power(cooccurrence_matrix, alpha)\n",
    "    \n",
    "    # Розрахунок PPMI з використанням згладжених значень\n",
    "    return calculate_ppmi_matrix(smoothed_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a35443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Корпус містить 100 документів\n",
      "\n",
      "Task 0: Bag-of-Words представлення\n",
      "Розмір словника: 1706\n",
      "Форма BoW векторів: (100, 1706)\n",
      "\n",
      "Task 1: Bag-of-Words з біграмами\n",
      "Кількість біграм: 6119\n",
      "Форма BoW-біграм векторів: (100, 6119)\n",
      "\n",
      "Task 2: PPMI на основі співзустрічань у параграфах\n",
      "Форма матриці співзустрічань: (1706, 1706)\n",
      "Форма матриці PPMI: (1706, 1706)\n",
      "\n",
      "Task 3: PPMI на основі вікна співзустрічань\n",
      "Форма матриці співзустрічань з вікном: (1706, 1706)\n",
      "Форма матриці PPMI з вікном: (1706, 1706)\n",
      "\n",
      "Task 4: Згладжене PPMI для рідких слів\n",
      "Форма згладженої матриці PPMI: (1706, 1706)\n",
      "\n",
      "Task 5: Аналіз семантично пов'язаних слів\n",
      "\n",
      "Найближчі слова до 'love':\n",
      "  goodness: 8.0818\n",
      "  surprized: 8.0818\n",
      "  fell: 8.0818\n",
      "  cease: 8.0818\n",
      "  nobody: 6.1943\n",
      "  wanted: 5.7599\n",
      "  husband: 5.2745\n",
      "  churchill: 4.9119\n",
      "  though: 4.6623\n",
      "  did: 4.2745\n",
      "\n",
      "Найближчі слова до 'happy':\n",
      "  months: 6.8594\n",
      "  square: 6.8594\n",
      "  brunswick: 6.8594\n",
      "  sending: 6.8594\n",
      "  collect: 6.8594\n",
      "  animated: 6.8594\n",
      "  unite: 6.8594\n",
      "  frequently: 6.8594\n",
      "  circumstance: 5.8594\n",
      "  fathers: 5.3740\n",
      "\n",
      "Найближчі слова до 'sad':\n",
      "  tis: 8.8029\n",
      "  warfare: 8.2883\n",
      "  business: 7.0252\n",
      "  feelings: 6.7033\n",
      "  done: 6.1184\n",
      "  loved: 5.9664\n",
      "  woodhouses: 5.4809\n",
      "  taylor: 4.8553\n",
      "  poor: 4.5441\n",
      "  herself: 4.2439\n",
      "\n",
      "Найближчі слова до 'good':\n",
      "  interference: 6.1495\n",
      "  property: 5.1495\n",
      "  thoroughly: 5.1495\n",
      "  wifeand: 5.1495\n",
      "  encouragement: 5.1495\n",
      "  parted: 5.1495\n",
      "  hannah: 5.1495\n",
      "  established: 5.1495\n",
      "  appreciating: 5.1495\n",
      "  residence: 5.1495\n",
      "\n",
      "Найближчі слова до 'bad':\n",
      "  detach: 9.6668\n",
      "  introduce: 9.6668\n",
      "  acquaintance: 6.9664\n",
      "  into: 6.4969\n",
      "  from: 4.5049\n",
      "  would: 4.5009\n",
      "  her: 4.0086\n",
      "  and: 1.3837\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Приклад тексту з корпусу Gutenberg\n",
    "    sample_text = gutenberg.raw('austen-emma.txt')\n",
    "    \n",
    "    # Розділення на документи (для простоти використовуємо параграфи)\n",
    "    paragraphs = [p for p in sample_text.split('\\n\\n') if p.strip()]\n",
    "    corpus = paragraphs[:100]  # Беремо перші 100 параграфів для прикладу\n",
    "    \n",
    "    print(f\"Корпус містить {len(corpus)} документів\")\n",
    "    \n",
    "    # Task 0: Створення Bag-of-Words представлення\n",
    "    bow_vectors, vocabulary, vocab_to_idx = create_bow_vectors(corpus)\n",
    "    print(f\"\\nTask 0: Bag-of-Words представлення\")\n",
    "    print(f\"Розмір словника: {len(vocabulary)}\")\n",
    "    print(f\"Форма BoW векторів: {np.array(bow_vectors).shape}\")\n",
    "    \n",
    "    # Task 1: Використання біграм замість слів\n",
    "    bigram_bow_vectors, bigrams, bigram_to_idx = create_ngram_bow_vectors(corpus, n=2)\n",
    "    print(f\"\\nTask 1: Bag-of-Words з біграмами\")\n",
    "    print(f\"Кількість біграм: {len(bigrams)}\")\n",
    "    print(f\"Форма BoW-біграм векторів: {np.array(bigram_bow_vectors).shape}\")\n",
    "    \n",
    "    # Task 2: Матриця співзустрічань у параграфах та PPMI\n",
    "    paragraph_cooccurrence_matrix, para_vocab, para_word_to_idx = create_paragraph_cooccurrence_matrix(corpus)\n",
    "    paragraph_ppmi_matrix = calculate_ppmi_matrix(paragraph_cooccurrence_matrix)\n",
    "    print(f\"\\nTask 2: PPMI на основі співзустрічань у параграфах\")\n",
    "    print(f\"Форма матриці співзустрічань: {paragraph_cooccurrence_matrix.shape}\")\n",
    "    print(f\"Форма матриці PPMI: {paragraph_ppmi_matrix.shape}\")\n",
    "    \n",
    "    # Task 3: Матриця співзустрічань у вікні і PPMI\n",
    "    window_cooccurrence_matrix, window_vocab, window_word_to_idx = create_window_cooccurrence_matrix(corpus, window_size=5)\n",
    "    window_ppmi_matrix = calculate_ppmi_matrix(window_cooccurrence_matrix)\n",
    "    print(f\"\\nTask 3: PPMI на основі вікна співзустрічань\")\n",
    "    print(f\"Форма матриці співзустрічань з вікном: {window_cooccurrence_matrix.shape}\")\n",
    "    print(f\"Форма матриці PPMI з вікном: {window_ppmi_matrix.shape}\")\n",
    "    \n",
    "    # Task 4: Згладжене PPMI для вирішення проблеми рідких слів\n",
    "    smoothed_ppmi_matrix = calculate_smoothed_ppmi_matrix(window_cooccurrence_matrix, alpha=0.75)\n",
    "    print(f\"\\nTask 4: Згладжене PPMI для рідких слів\")\n",
    "    print(f\"Форма згладженої матриці PPMI: {smoothed_ppmi_matrix.shape}\")\n",
    "    \n",
    "    # Task 5: Порівняння з тезаурусом для декількох слів\n",
    "    common_words = ['love', 'happy', 'sad', 'good', 'bad']\n",
    "    words_in_vocab = [w for w in common_words if w in para_word_to_idx]\n",
    "    \n",
    "    if words_in_vocab:\n",
    "        print(f\"\\nTask 5: Аналіз семантично пов'язаних слів\")\n",
    "        for word in words_in_vocab:\n",
    "            word_idx = para_word_to_idx[word]\n",
    "            \n",
    "            # Отримання найближчих слів за PPMI\n",
    "            ppmi_scores = window_ppmi_matrix[word_idx]\n",
    "            top_indices = np.argsort(ppmi_scores)[::-1][:10]  # Топ-10 слів\n",
    "            \n",
    "            print(f\"\\nНайближчі слова до '{word}':\")\n",
    "            for idx in top_indices:\n",
    "                if ppmi_scores[idx] > 0:\n",
    "                    print(f\"  {window_vocab[idx]}: {ppmi_scores[idx]:.4f}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
